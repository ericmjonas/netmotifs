\documentclass{article}
\usepackage[english,american]{babel}
\usepackage[disable]{todonotes}
\usepackage{subfiles}
\usepackage{grffile}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{multicol}

\title{Neural Circuit Discovery}
\author{Eric Jonas \\ Konrad Kording}

\begin{document}
\maketitle

\listoftodos

\begin{abstract}
  The brain is made out of multiple types of neurons, and a neuronâ€™s
  type affects both its behavior and which other neurons it connects
  to. Emerging techniques (connectomics) allow measuring the
  connectivity matrix between many neurons. Estimating types from
  connectomics is difficult as distance is usually more important than
  type. Here we describe a nonparametric Bayesian technique that
  overcomes this problem and discovers neuron types based on
  connections only. We show that the approach recovers known neuron
  types in the retina, reveals interesting structure in the nervous
  system of c. elegans, and automatically discovers the structure of
  microprocessors. Extracting meaningful structure from connectivity
  data promises to enable new experiments and to constrain theories of
  brain function.

\end{abstract}

\section{Introduction}
Computing systems, biological or human-engineered, contain computing
elements that can be classified into ``type'', which give
insight into function. 

The rise of connectomics data allows discovery of cell types
based on connectivity information. 

Here we describe a Bayesian non-parametric model that can discover
both the cell types and their patterns of interconnection automatically
from connectomics data. 

We apply it to the recently-released mouse retina connectome, the
c. elegans connectome, and a ``connectome'' obtained by
reverse-engineering a portion of a classical microprocessor.


\section{Methods}
Stochastic block models assume a hidden or ``latent'' type is associated
wtih each node that ultimately influences its connectivity. 

We extend this class of model to incorporate notions of spatial locality, 
as the connectivity of many neural systems is substantially constrained. 

We perform posterior inference in this model using a series of Markov-chain
Monte Carlo techniques. 

\section{Results}

\subsection{Synthetic Data}
We show our model works by generating synthetic data with known spatial/connectivity patterns and recovering ground truth, even when the generating process makes assumptions very different from our model. 

\subsubsection{Mouse Retina}
When applied to the mouse retina dataset, we recover spatially-homogeneous patterns of activity that reflect a coarsening of ground truth. 

\subsection{C. elegans}
When applied to c. elegans, we segregate ``head and sensor'' interneurons from the spatially-distributed neurons along the body axis. 

\subsection{Microprocessor}

We recover the logical structure of the three primary registers of the
MOS6502 integrated circuit.


\section{Discussion}


\end{document}
